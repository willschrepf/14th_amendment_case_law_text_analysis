---
title: "basic_stats"
author: "Will Schrepferman"
date: "10/22/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
library("rjson")
library("tidyjson")
library("glue")
library("skimr")
library("openxlsx")
```

```{r read_data_one_case}
# testing functionality of reading one single json file into a tibble row

json_file <- "school-segregation-cases/1000012.json"

# using rjson package functionality
json_data <- fromJSON(file=json_file)


# these two methods are obtional, but make the data a little uglier
# data_flat <- flatten(json_data)
# data_tbl <- as_tibble(data_flat)

# read only the elements we need from their place in the json object
full_text <- json_data$clusters[[1]]$sub_opinions[[1]]$html_lawbox[1]
id <- json_data$id
resource_uri <- json_data$resource_uri
court_raw <- json_data$court
judges <- json_data$clusters[[1]]$judges[1]
date_filed <- json_data$clusters[[1]]$date_filed[1]
slug <- json_data$clusters[[1]]$slug
federal_cite <- json_data$clusters[[1]]$federal_cite_one[1]


# put items into a tibble row
tibble_data <- tibble(id = id, slug = slug, date_filed = date_filed, court_raw = court_raw, judges = judges, federal_cite = federal_cite,
                      full_text = full_text, resource_uri = resource_uri)
```




```{r read_data_multiple_cases}
# list of all files
files <- list.files("school-segregation-cases")

# function to read one file into a coherent row
readfile <- function(file){
  
  # get the whole file
  json_file <- glue("school-segregation-cases/", file, sep = "")

  # using rjson package functionality
  json_data <- fromJSON(file=json_file)
  
  # these two methods are optional, but make the data a little uglier
  # data_flat <- flatten(json_data)
  # data_tbl <- as_tibble(data_flat)
  
  # read only the elements we need from their place in the json object
  full_text <- json_data$clusters[[1]]$sub_opinions[[1]]$html_lawbox[1]
  id <- json_data$id
  resource_uri <- json_data$resource_uri
  court_raw <- json_data$court
  judges <- json_data$clusters[[1]]$judges[1]
  date_filed <- json_data$clusters[[1]]$date_filed[1]
  slug <- json_data$clusters[[1]]$slug
  federal_cite <- json_data$clusters[[1]]$federal_cite_one[1]
  
  
  # put items into a tibble row
  tibble_data <- tibble(id = id, slug = slug, date_filed = date_filed, court_raw = court_raw, judges = judges, federal_cite = federal_cite,
                      full_text = full_text, resource_uri = resource_uri)
}

# make an empty tibble to put everything in
data_complete <- tibble()


for(i in files){
  # add tibble row from the function onto the final tibble
  data_complete <- rbind(data_complete, readfile(i))
}

tail(data_complete)

# ERROR: running the method above hits a snag when you get to file id 3032772
# will run analysis on the 8287 of 13572 objects that made their way into data frame

skim(data_complete)

head(data_complete, n = 100)

# filter out only cases for which we have all variables

none_missing_data_complete <- data_complete %>%
  filter(judges != "" & federal_cite != "" & full_text != "")

# create a set of cases with at least 1 incomplete field to export for review

incomplete_cases <- data_complete %>%
  filter(judges == "" | federal_cite == "" | full_text == "")

incomplete_cases <- incomplete_cases %>%
  mutate_if(is.character, list(~na_if(.,""))) 

skim(incomplete_cases)
head(incomplete_cases)

write.xlsx(incomplete_cases, "incomplete_cases_export.xlsx")

# 3593 of 8287 (43.4%)

# To-Do:
# Discuss which cases to exclude - DONE
# Resolve error that only gives me half of the data set - TRIED FOR AN HOUR AND COULD NOT RESOLVE
# create a 'document length' variable
# mapping court_raw to an actual court variable -> go to court listener
# export list of incomplete cases - DONE
```

```{r text_cleaning}
# create testing data with only 25 cases for computing speed purposes

test_data <- head(none_missing_data_complete, 25)

# add variables for year, clean up date type, cut fluff from court type
test_data <- test_data %>%
  mutate(year = as.numeric(substr(date_filed, start = 1, stop = 4))) %>%
  mutate(exact_date = as.Date(date_filed)) %>%
  mutate(court = substr(court_raw, start = 53, stop = (nchar(court_raw)-1))) %>%
  select(id, slug, year, court, judges, federal_cite, full_text, exact_date, resource_uri)

# get an idea of document word counts pre-clean

test_data <- test_data %>%
  mutate(doc_length_pre_clean = sapply(strsplit(full_text, " "), length))

test_data <- test_data %>%
  mutate(clean_text = str_replace_all(full_text, "[^[:alnum:]]", " ")) %>%
  mutate(clean_text = str_replace_all(clean_text, "^div center b ", "")) %>%
  select(id, slug, year, court, judges, federal_cite, clean_text, exact_date, resource_uri)

```



```{r read_data_tidy}
# This approach yielded poor results
json_file <- "school-segregation-cases/1000012.json"
json_data <- fromJSON(file=json_file)
json_data %>% spread_all
```


