---
title: "sentiment_analysis"
author: "Will Schrepferman"
date: "2/27/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
library("rjson")
library("tidyjson")
library("glue")
library("gt")
library("skimr")
library("openxlsx")
library("tidytext")
library("SnowballC")
library("rvest")
library("janitor")
library("ggplot2")
library("tidytext")
library("tidyr")
library("topicmodels")
library("keras")
library("janeaustenr")
library("tokenizers")
library('forcats')
```

```{r}

## DO INTEGRATION AS TERM


corpus_relevant_modified <- read_csv("full_corpus.csv") %>%
  mutate(cleaned_text = str_replace_all(tolower(clean_text), "[[:punct:]]", " ")) %>%
  select(id, slug, year, judges, federal_cite, cleaned_text, doc_length_post_clean, exact_date, resource_uri)

cleaned_dictionary <- corpus_relevant_modified %>%
  unnest_tokens(word, cleaned_text) %>%
  mutate(term = wordStem(word)) %>%
  anti_join(stop_words)

# function to get sentiment of a given list of words


get_sentiment <- function(tibble){
  num_words <- tibble %>%
      count() %>%
      pull()
  
  sentiment <- tibble %>%
  
  select(word) %>%
  
  inner_join(get_sentiments("bing")) %>%
      
    # count the number of positive & negative words
    
    count(sentiment) %>%
    
    # make data wide rather than narrow
    
    spread(sentiment, n, fill = 0) %>%
    
    # number of positive words minus number of negative words divided by total words
    
    mutate(sentiment = ((positive - negative)/as.double(num_words)))
  
  return(sentiment)
  
}

# generate variables for words surrounding the term 'segreg'


surrounding_words1 <- cleaned_dictionary %>%
  anti_join(stop_words)

surrounding_words1$rownum <- as.numeric(rownames(surrounding_words1)) 

surrounding_words <- surrounding_words1 %>%
  mutate(wn1 = lag(word, 1)) %>%
  mutate(wn2 = lag(word, 2)) %>%
  mutate(wn3 = lag(word, 3)) %>%
  mutate(wn4 = lag(word, 4)) %>%
  mutate(wn5 = lag(word, 5)) %>%
  mutate(wn6 = lag(word, 6)) %>%
  mutate(wn7 = lag(word, 7)) %>%
  mutate(wn8 = lag(word, 8)) %>%
  mutate(wn9 = lag(word, 9)) %>%
  mutate(wn10 = lag(word, 10)) %>%
  mutate(w1 = lead(word, 1)) %>%
  mutate(w2 = lead(word, 2)) %>%
  mutate(w3 = lead(word, 3)) %>%
  mutate(w4 = lead(word, 4)) %>%
  mutate(w5 = lead(word, 5)) %>%
  mutate(w6 = lead(word, 6)) %>%
  mutate(w7 = lead(word, 7)) %>%
  mutate(w8 = lead(word, 8)) %>%
  mutate(w9 = lead(word, 9)) %>%
  mutate(w10 = lead(word, 10)) %>%
  mutate(surrounding_raw = paste(wn10, wn9, wn8, wn7, wn6, wn5, wn4, wn3, wn2, wn1, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10)) %>%
  select(-wn1, -wn2, -wn3, -wn4, -wn5, -wn6, -wn7, -wn8, -wn9, -wn10, -w1, -w2, -w3, -w4, -w5, w6, -w7, -w8, -w9, -w10)

surrounding_words_filt <- surrounding_words %>%
  filter(term == "segreg")

l_s <- surrounding_words_filt$rownum

surrounding_sentiments <- tibble(rownum = 0, context_sent = 0)

# identify the sentiment of each set of surrounding words and put into surrounding_sentiments tibble

for (i in l_s){
  word_instance <- surrounding_words$word[i]
  surrounding_list = strsplit(surrounding_words$surrounding_raw[i], '\\s+')[[1]]
  surrounding_tibble = as_tibble_col(surrounding_list, column_name = "word")
  surrounding_tibble1 <- surrounding_tibble %>%
  
    select(word) %>%
    
    add_row(word = "2-faces") %>%
    
    add_row(word = "zippy") %>%
    
    inner_join(get_sentiments("bing")) %>%
        
    # count the number of positive & negative words
    
    count(sentiment) %>%
    
    # make data wide rather than narrow
    
    spread(sentiment, n, fill = 0) %>%
  
    mutate(sentiment = (positive - negative)/as.double(20))
  
  s_val <- surrounding_tibble1$sentiment
  
  surrounding_sentiments <- surrounding_sentiments%>%
    add_row(rownum = i, context_sent = s_val)
  
}


full_context_sentiments <- surrounding_words_filt %>%
  left_join(surrounding_sentiments, by = "rownum")

# plot full surrounding sentiments
  
plot <- full_context_sentiments %>%
  group_by(year) %>%
  summarize(overall_sent = mean(context_sent, na.rm = TRUE)) %>%
  ggplot(aes(x = year, y = overall_sent)) +
  geom_line() +
  geom_point(size=1) +
  labs(title = "Sentiment Surrounding Segregation Over Time", subtitle = "Using Sentiment Analysis on Surrounding Word Context of the Term 'segreg'", y = "Average Sentiment", x = "Year") +
  geom_smooth(method = "lm")

# testing data quality

full_context_sentiments %>%
  group_by(year) %>%
  summarize(sum = sum(context_sent), count = n(), other_avg = sum/count, avg = mean(context_sent, na.rm = TRUE))

# now, filtering for top 10 adjectives to generate heat maps

cleaned_dictionary_adj <- cleaned_dictionary %>%
  inner_join(parts_of_speech) %>%
  filter(pos == "Adjective") %>%
  inner_join(get_sentiments("bing"))

top10_pos_adj <- cleaned_dictionary_adj %>%
  group_by(word, sentiment) %>%
  summarize(count = n()) %>%
  filter(sentiment == "positive") %>%
  filter(word != "supreme") %>%
  arrange(-count) %>%
  head(10)

top10_neg_adj <- cleaned_dictionary_adj %>%
  group_by(word, sentiment) %>%
  summarize(count = n()) %>%
  filter(sentiment == "negative") %>%
  filter(word != "supreme") %>%
  arrange(-count) %>%
  head(10)

top_10_pos_adj_yearly <- cleaned_dictionary_adj %>%
  filter(word %in% top10_pos_adj$word) %>%
  group_by(word, year) %>%
  summarise(n = n()) %>%
  mutate(percentage = n/sum(n)) %>%
  ungroup() %>%
  add_row(word = "affirmative", year = 1956, n = 0, percentage = 0) %>%
  add_row(word = "significant", year = 1960, n = 0, percentage = 0) %>%
  arrange(word, year)



pos_plot <- top_10_pos_adj_yearly %>%
  ggplot(aes(x = year, y = percentage, fill = word)) +
  geom_area(position = "fill") + 
  labs(title = "Top Ten Positive Adjectives in Corpus", subtitle = "As a Percentage Over Time 1950-1974", x = "Year", y = "Percentage")

top_10_neg_adj_yearly <- cleaned_dictionary_adj %>%
  filter(word %in% top10_neg_adj$word) %>%
  group_by(word, year) %>%
  summarise(n = n()) %>%
  mutate(percentage = n/sum(n)) %>%
  ungroup() %>%
  add_row(word = "arbitrary", year = 1950, n = 0, percentage = 0) %>%
  add_row(word = "arbitrary", year = 1956, n = 0, percentage = 0) %>%
  add_row(word = "arbitrary", year = 1959, n = 0, percentage = 0) %>%
  add_row(word = "confined", year = 1954, n = 0, percentage = 0) %>%
  add_row(word = "difficult", year = 1954, n = 0, percentage = 0) %>%
  add_row(word = "discriminatory", year = 1950, n = 0, percentage = 0) %>%
  add_row(word = "discriminatory", year = 1954, n = 0, percentage = 0) %>%
  add_row(word = "guilty", year = 1954, n = 0, percentage = 0) %>%
  add_row(word = "unable", year = 1954, n = 0, percentage = 0) %>%
  add_row(word = "unconstitutional", year = 1953, n = 0, percentage = 0) %>%
  arrange(word, year)

neg_plot <- top_10_neg_adj_yearly %>%
  ggplot(aes(x = year, y = percentage, fill = word)) +
  geom_area(position = "fill") +
  labs(title = "Top Ten Negative Adjectives in Corpus", subtitle = "As a Percentage Over Time 1950-1974", x = "Year", y = "Percentage")
  
# confined 1954 0 0
# difficult 1954 0 0
# discriminatory 1954 0 0
# guilty 1954 0 0 
# unable 1954 0 0
# unconstitutional 1953 0 0
```






```{r}
surrounding_words_filt <- surrounding_words %>%
  filter(term == "integr") %>%
  filter(word != "integrity") %>%
  filter(word != "integral")

l_s <- surrounding_words_filt$rownum

surrounding_sentiments <- tibble(rownum = 0, context_sent = 0)

# identify the sentiment of each set of surrounding words and put into surrounding_sentiments tibble

for (i in l_s){
  word_instance <- surrounding_words$word[i]
  surrounding_list = strsplit(surrounding_words$surrounding_raw[i], '\\s+')[[1]]
  surrounding_tibble = as_tibble_col(surrounding_list, column_name = "word")
  surrounding_tibble1 <- surrounding_tibble %>%
  
    select(word) %>%
    
    add_row(word = "2-faces") %>%
    
    add_row(word = "zippy") %>%
    
    inner_join(get_sentiments("bing")) %>%
        
    # count the number of positive & negative words
    
    count(sentiment) %>%
    
    # make data wide rather than narrow
    
    spread(sentiment, n, fill = 0) %>%
  
    mutate(sentiment = (positive - negative)/as.double(20))
  
  s_val <- surrounding_tibble1$sentiment
  
  surrounding_sentiments <- surrounding_sentiments%>%
    add_row(rownum = i, context_sent = s_val)
  
}


full_context_sentiments <- surrounding_words_filt %>%
  left_join(surrounding_sentiments, by = "rownum")

# plot full surrounding sentiments
  
plot <- full_context_sentiments %>%
  filter(year != 1951) %>%
  group_by(year) %>%
  summarize(overall_sent = mean(context_sent, na.rm = TRUE)) %>%
  ggplot(aes(x = year, y = overall_sent)) +
  geom_line() +
  geom_point(size=1) +
  labs(title = "Sentiment Surrounding Integration Over Time", subtitle = "Using Sentiment Analysis on Surrounding Word Context of the Term 'Integr'", y = "Average Sentiment", x = "Year") +
  geom_smooth(method = "lm")

# testing data quality

full_context_sentiments %>%
  group_by(year) %>%
  summarize(sum = sum(context_sent), count = n(), other_avg = sum/count, avg = mean(context_sent, na.rm = TRUE))
```


